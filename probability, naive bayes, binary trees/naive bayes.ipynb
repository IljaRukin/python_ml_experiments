{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## naive bayes\n",
    "\n",
    "naive bayes is used for binary classification, for example to predict if a message is spam or not depending on the words included in the message.\n",
    "For each word W we can use the bayes theorem to compute the probabilty of the message beeing spam S.\n",
    "\n",
    "\\begin{equation}\n",
    "P(S|W) = \\frac{P(W|S) \\cdot P(S)}{P(W)}\n",
    "\\end{equation}\n",
    "\n",
    "with the assumption, that the words inside a message $w_1,...,w_n$ occur independent on each other:\n",
    "\n",
    "\\begin{equation}\n",
    "P(W=w_1,...,w_n|S) = P(W=w_1|S) \\cdot ... \\cdot P(W=w_n|S)\n",
    "\\end{equation}\n",
    "\n",
    "We can compute the Probability of a message being spam dependent on n words inside the message.\n",
    "\n",
    "\n",
    "\\begin{equation}\n",
    "P(S|W) = \\frac{P(W=w_1,...,w_n|S) \\cdot P(S)}{P(W=w_1,...,w_n)} \\\\\n",
    "= \\frac{P(W=w_1|S) \\cdot ... \\cdot P(W=w_n|S) \\cdot P(S)}{P(W=w_1) \\cdot ... \\cdot P(W=w_n)}\n",
    "\\end{equation}\n",
    "\n",
    "-----\n",
    "\n",
    "### note:\n",
    "\n",
    "Usually the product of the probabilities $P(W=w_1|S) \\cdot ... \\cdot P(W=w_n|S)$ is computed using logarithms $e^{\\log{P(W=w_1|S)} + ... + \\log{P(W=w_n|S)}}$ to avoid underflow (small numbers).\n",
    "\n",
    "To avoid a probability of zero, because a word $w_i$ previously never occured in a spam message the probabilities are slightly modified. for example\n",
    "\n",
    "\\begin{equation}\n",
    "P(w_i|S) = \\frac{n\\_w_i + n\\_of\\_spams\\_with\\_w_i}{2 \\cdot n\\_w_i + n\\_of\\_spams}\n",
    "\\end{equation}\n",
    "\n",
    "Also the denominator is often discarded. Then the probability for a positive (spam) and negative (no spam) has to be computed and compared.\n",
    "\n",
    "---\n",
    "\n",
    "## continous distributions (gaussian)\n",
    "\n",
    "If features $w_i$ are contiously distributed, like the time when the message was sent or it's size, we need to modify our approach. We split the datapoints for each feature into two groups (datapoints for positive and negative examples (messages with and without spam)). Then we assume a normal (gaussian) distribution of the datapoints of each group. We compute the mean and standard deviation for both groups. \n",
    "\n",
    "\\begin{equation}\n",
    "\\mu = \\sum_{i=1}^{N} \\frac{x_i}{N} \\\\\n",
    "\\sigma^2 = \\sum_{i=1}^{N} \\frac{(x-\\mu)^2}{N}\n",
    "\\end{equation}\n",
    "\n",
    "Now for a new datapoint we can compute the probability of it belonging to the positive or negative group (messages with and without spam) with the formula for the normal distribution\n",
    "\n",
    "\\begin{equation}\n",
    "P(x) = \\frac{1}{\\sigma\\sqrt{2 \\pi}} e^{-\\frac{1}{2}\\left(\\frac{x-\\mu}{\\sigma}\\right)^2}\n",
    "\\end{equation}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of mislabeled points out of a total 75 points : 4\n"
     ]
    }
   ],
   "source": [
    "#bayesian (gaussian) inference for iris dataset\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "X, y = load_iris(return_X_y=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=0)\n",
    "gnb = GaussianNB()\n",
    "y_pred = gnb.fit(X_train, y_train).predict(X_test)\n",
    "print(\"Number of mislabeled points out of a total %d points : %d\"\n",
    "      % (X_test.shape[0], (y_test != y_pred).sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
