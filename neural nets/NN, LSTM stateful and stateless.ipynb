{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NN, LSTM\n",
    "example from: http://philipperemy.github.io/keras-stateful-lstm/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once deleted, variables cannot be recovered. Proceed (y/[n])? y\n"
     ]
    }
   ],
   "source": [
    "%reset -f\n",
    "import numpy as np\n",
    "from keras.callbacks import Callback\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_sequences(x_train, y_train, window_length):\n",
    "    windows = []\n",
    "    windows_y = []\n",
    "    for i, sequence in enumerate(x_train):\n",
    "        len_seq = len(sequence)\n",
    "        for window_start in range(0, len_seq - window_length + 1):\n",
    "            window_end = window_start + window_length\n",
    "            window = sequence[window_start:window_end]\n",
    "            windows.append(window)\n",
    "            windows_y.append(y_train[i])\n",
    "    return np.array(windows), np.array(windows_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test data\n",
    "random 0/1 in X[num_samples,time_steps] <br>\n",
    "expected result Y=X[:,0] <br>\n",
    "for example X=[[1,0],[0,0],[0,0],[1,0]], Y=[1,0,0,1]. <br>\n",
    "data is fed into the LSTM classifier in smaller pieces than \"time_steps\", hence the classifier has to remember it's previous state to be better than just guessing (p=0.5)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_steps = 20\n",
    "num_train_samples = 1000\n",
    "num_test_samples = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-allocating the numpy array for better readability\n",
    "X_train = np.zeros((num_train_samples, time_steps, 1), dtype=int)\n",
    "X_test = np.zeros((num_test_samples, time_steps, 1), dtype=int)\n",
    "y_train = np.zeros((num_train_samples), dtype=int)\n",
    "y_test = np.zeros((num_test_samples), dtype=int)\n",
    "\n",
    "# Setting internal time-steps to random numbers\n",
    "X_train[:, 1:] = np.random.randint(0, 2, (num_train_samples, time_steps-1, 1), dtype=int)\n",
    "X_test[:, 1:] = np.random.randint(0, 2, (num_test_samples, time_steps-1, 1), dtype=int)\n",
    "# Setting half of the first time-steps to 1\n",
    "one_indexes = np.random.choice(a=num_train_samples, size=int(num_train_samples / 2), replace=False)\n",
    "X_train[one_indexes, 0] = 1\n",
    "one_indexes = np.random.choice(a=num_test_samples, size=int(num_test_samples / 2), replace=False)\n",
    "X_test[one_indexes, 0] = 1\n",
    "\n",
    "# Creating labels\n",
    "y_train = X_train[:, 0, 0]\n",
    "y_test = X_test[:, 0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1000, 20, 1), (1000,), (200, 20, 1), (200,))"
      ]
     },
     "execution_count": 333,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1],\n",
       "        [1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1],\n",
       "        [1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0],\n",
       "        [1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0],\n",
       "        [0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0]]),\n",
       " array([0, 1, 1, 1, 0]))"
      ]
     },
     "execution_count": 334,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0:5,:,0], y_train[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_sub, y_train_sub = prepare_sequences(X_train, y_train, window_length=10)\n",
    "X_test_sub, y_test_sub = prepare_sequences(X_test, y_test, window_length=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((11000, 10, 1), (11000,), (2200, 10, 1), (2200,))"
      ]
     },
     "execution_count": 350,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_sub.shape, y_train_sub.shape, X_test_sub.shape, y_test_sub.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1]]),\n",
       " array([0, 1, 1, 1, 0, 1]))"
      ]
     },
     "execution_count": 351,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_sub[(0,11,22,33,44,55),0], y_train_sub[(0,11,22,33,44,55),]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.expand_dims(np.expand_dims(X_train.flatten(), axis=1), axis=1)\n",
    "y = np.expand_dims(np.array([[v] * 20 for v in y_train.flatten()]).flatten(), axis=1)\n",
    "xx = np.expand_dims(np.expand_dims(X_test.flatten(), axis=1), axis=1)\n",
    "yy = np.expand_dims(np.array([[v] * 20 for v in y_test.flatten()]).flatten(), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((20000, 1, 1), (20000, 1), (4000, 1, 1), (4000, 1))"
      ]
     },
     "execution_count": 364,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape, y.shape, xx.shape, yy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 0, 0, 1, 0, 0, 1, 0, 1, 0]), array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0]))"
      ]
     },
     "execution_count": 366,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0:10,0,0], y[0:10,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## simple LSTM model\n",
    "does not remember states between samples, not effective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_63\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_46 (LSTM)               (None, 5)                 140       \n",
      "_________________________________________________________________\n",
      "dense_71 (Dense)             (None, 1)                 6         \n",
      "=================================================================\n",
      "Total params: 146\n",
      "Trainable params: 146\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 1000 samples, validate on 200 samples\n",
      "Epoch 1/5\n",
      "1000/1000 [==============================] - 7s 7ms/sample - loss: 0.6949 - accuracy: 0.4800 - val_loss: 0.6930 - val_accuracy: 0.5000\n",
      "Epoch 2/5\n",
      "1000/1000 [==============================] - 5s 5ms/sample - loss: 0.6945 - accuracy: 0.4770 - val_loss: 0.6935 - val_accuracy: 0.5000\n",
      "Epoch 3/5\n",
      "1000/1000 [==============================] - 5s 5ms/sample - loss: 0.6940 - accuracy: 0.4890 - val_loss: 0.6940 - val_accuracy: 0.5000\n",
      "Epoch 4/5\n",
      "1000/1000 [==============================] - 5s 5ms/sample - loss: 0.6937 - accuracy: 0.4840 - val_loss: 0.6944 - val_accuracy: 0.5000\n",
      "Epoch 5/5\n",
      "1000/1000 [==============================] - 5s 5ms/sample - loss: 0.6933 - accuracy: 0.4960 - val_loss: 0.6949 - val_accuracy: 0.4950\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1cd5e2fddc8>"
      ]
     },
     "execution_count": 369,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = Sequential()\n",
    "m.add(LSTM(5, input_shape=(20, 1), stateful=False))\n",
    "m.add(Dense(1, activation='sigmoid'))\n",
    "#m.compile(loss='MSE', optimizer='adam', metrics=['accuracy'])\n",
    "m.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(m.summary())\n",
    "m.fit(X_train, y_train, batch_size=1, epochs=5, shuffle=False, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_69\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_52 (LSTM)               (None, 5)                 140       \n",
      "_________________________________________________________________\n",
      "dense_77 (Dense)             (None, 1)                 6         \n",
      "=================================================================\n",
      "Total params: 146\n",
      "Trainable params: 146\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 11000 samples, validate on 2200 samples\n",
      "Epoch 1/5\n",
      "11000/11000 [==============================] - 6s 558us/sample - loss: 0.6944 - accuracy: 0.5012 - val_loss: 0.6947 - val_accuracy: 0.5000\n",
      "Epoch 2/5\n",
      "11000/11000 [==============================] - 5s 434us/sample - loss: 0.6946 - accuracy: 0.4856 - val_loss: 0.6945 - val_accuracy: 0.5000\n",
      "Epoch 3/5\n",
      "11000/11000 [==============================] - 5s 410us/sample - loss: 0.6945 - accuracy: 0.4877 - val_loss: 0.6943 - val_accuracy: 0.5000\n",
      "Epoch 4/5\n",
      "11000/11000 [==============================] - 5s 413us/sample - loss: 0.6944 - accuracy: 0.4872 - val_loss: 0.6941 - val_accuracy: 0.5000\n",
      "Epoch 5/5\n",
      "11000/11000 [==============================] - 5s 413us/sample - loss: 0.6943 - accuracy: 0.4845 - val_loss: 0.6940 - val_accuracy: 0.5000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1cd67f030c8>"
      ]
     },
     "execution_count": 375,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = Sequential()\n",
    "m.add(LSTM(5, input_shape=(10, 1), stateful=False))\n",
    "m.add(Dense(1, activation='sigmoid'))\n",
    "#m.compile(loss='MSE', optimizer='adam', metrics=['accuracy'])\n",
    "m.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(m.summary())\n",
    "m.fit(X_train_sub, y_train_sub, batch_size=11, epochs=5, shuffle=False, validation_data=(X_test_sub, y_test_sub))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_70\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_53 (LSTM)               (None, 5)                 140       \n",
      "_________________________________________________________________\n",
      "dense_78 (Dense)             (None, 1)                 6         \n",
      "=================================================================\n",
      "Total params: 146\n",
      "Trainable params: 146\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 20000 samples, validate on 4000 samples\n",
      "Epoch 1/5\n",
      "20000/20000 [==============================] - 6s 298us/sample - loss: 7.7125 - accuracy: 0.5000 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 2/5\n",
      "20000/20000 [==============================] - 4s 212us/sample - loss: 7.7125 - accuracy: 0.5000 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 3/5\n",
      "20000/20000 [==============================] - 4s 219us/sample - loss: 7.7125 - accuracy: 0.5000 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 4/5\n",
      "20000/20000 [==============================] - 5s 247us/sample - loss: 7.7125 - accuracy: 0.5000 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 5/5\n",
      "20000/20000 [==============================] - 5s 240us/sample - loss: 7.7125 - accuracy: 0.5000 - val_loss: 7.7125 - val_accuracy: 0.5000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1cd6b368808>"
      ]
     },
     "execution_count": 376,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = Sequential()\n",
    "m.add(LSTM(5, input_shape=(1, 1), stateful=False))\n",
    "m.add(Dense(1, activation='relu'))\n",
    "m.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(m.summary())\n",
    "m.fit(x, y, batch_size=20, epochs=5, shuffle=False, validation_data=(xx, yy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple NN\n",
    "simplest model, works for this simple example by connectin x[0] to y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_94\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_9 (Flatten)          (None, 20)                0         \n",
      "_________________________________________________________________\n",
      "dense_102 (Dense)            (None, 5)                 105       \n",
      "_________________________________________________________________\n",
      "dense_103 (Dense)            (None, 1)                 6         \n",
      "=================================================================\n",
      "Total params: 111\n",
      "Trainable params: 111\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 1000 samples, validate on 200 samples\n",
      "Epoch 1/15\n",
      "1000/1000 [==============================] - 1s 569us/sample - loss: 0.7093 - accuracy: 0.5360 - val_loss: 0.6746 - val_accuracy: 0.5350\n",
      "Epoch 2/15\n",
      "1000/1000 [==============================] - 0s 180us/sample - loss: 0.6559 - accuracy: 0.6050 - val_loss: 0.6420 - val_accuracy: 0.6300\n",
      "Epoch 3/15\n",
      "1000/1000 [==============================] - 0s 170us/sample - loss: 0.6287 - accuracy: 0.6620 - val_loss: 0.6139 - val_accuracy: 0.6550\n",
      "Epoch 4/15\n",
      "1000/1000 [==============================] - 0s 180us/sample - loss: 0.5918 - accuracy: 0.7420 - val_loss: 0.5674 - val_accuracy: 0.7300\n",
      "Epoch 5/15\n",
      "1000/1000 [==============================] - 0s 190us/sample - loss: 0.5377 - accuracy: 0.8140 - val_loss: 0.5157 - val_accuracy: 0.8250\n",
      "Epoch 6/15\n",
      "1000/1000 [==============================] - 0s 190us/sample - loss: 0.4831 - accuracy: 0.8830 - val_loss: 0.4633 - val_accuracy: 0.8850\n",
      "Epoch 7/15\n",
      "1000/1000 [==============================] - 0s 230us/sample - loss: 0.4313 - accuracy: 0.9290 - val_loss: 0.4133 - val_accuracy: 0.9350\n",
      "Epoch 8/15\n",
      "1000/1000 [==============================] - 0s 170us/sample - loss: 0.3820 - accuracy: 0.9630 - val_loss: 0.3645 - val_accuracy: 1.0000\n",
      "Epoch 9/15\n",
      "1000/1000 [==============================] - 0s 170us/sample - loss: 0.3351 - accuracy: 0.9900 - val_loss: 0.3182 - val_accuracy: 1.0000\n",
      "Epoch 10/15\n",
      "1000/1000 [==============================] - 0s 200us/sample - loss: 0.2906 - accuracy: 0.9960 - val_loss: 0.2759 - val_accuracy: 1.0000\n",
      "Epoch 11/15\n",
      "1000/1000 [==============================] - 0s 240us/sample - loss: 0.2511 - accuracy: 0.9990 - val_loss: 0.2388 - val_accuracy: 1.0000\n",
      "Epoch 12/15\n",
      "1000/1000 [==============================] - 0s 210us/sample - loss: 0.2173 - accuracy: 1.0000 - val_loss: 0.2070 - val_accuracy: 1.0000\n",
      "Epoch 13/15\n",
      "1000/1000 [==============================] - 0s 170us/sample - loss: 0.1884 - accuracy: 1.0000 - val_loss: 0.1795 - val_accuracy: 1.0000\n",
      "Epoch 14/15\n",
      "1000/1000 [==============================] - 0s 240us/sample - loss: 0.1638 - accuracy: 1.0000 - val_loss: 0.1561 - val_accuracy: 1.0000\n",
      "Epoch 15/15\n",
      "1000/1000 [==============================] - 0s 260us/sample - loss: 0.1430 - accuracy: 1.0000 - val_loss: 0.1363 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1cd81658108>"
      ]
     },
     "execution_count": 458,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = Sequential()\n",
    "m.add(Flatten(input_shape=(time_steps, 1)))\n",
    "m.add(Dense(5, activation='relu'))\n",
    "m.add(Dense(1, activation='sigmoid'))\n",
    "m.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(m.summary())\n",
    "m.fit(X_train, y_train, batch_size=20, epochs=15, shuffle=False, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## stateful LSTM\n",
    "effective with storing state inside 20 samples and reset of values afterwards<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build STATEFUL model...\n"
     ]
    }
   ],
   "source": [
    "print('Build STATEFUL model...')\n",
    "model = Sequential()\n",
    "model.add(LSTM(10, batch_input_shape=(1, 1, 1), return_sequences=False, stateful=True))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class MyCustomCallback(Callback):\n",
    "    def __init__(self):\n",
    "        #self.counter = 0\n",
    "        return None\n",
    "    \n",
    "    def on_train_batch_begin(self, batch, logs=None):\n",
    "        if batch%20 == 0:\n",
    "            self.model.reset_states()\n",
    "\n",
    "    def on_train_batch_end(self, batch, logs=None):\n",
    "        return None\n",
    "\n",
    "    def on_test_batch_begin(self, batch, logs=None):\n",
    "        if batch%20 == 0:\n",
    "            self.model.reset_states()\n",
    "\n",
    "    def on_test_batch_end(self, batch, logs=None):\n",
    "        return None\n",
    "    \n",
    "    def on_test_begin(self, batch, logs=None):\n",
    "        return None\n",
    "    \n",
    "    def on_test_end(self, batch, logs=None):\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20000 samples, validate on 4000 samples\n",
      "Epoch 1/2\n",
      "20000/20000 [==============================] - 92s 5ms/sample - loss: 0.4736 - accuracy: 0.7002 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
      "Epoch 2/2\n",
      "20000/20000 [==============================] - 84s 4ms/sample - loss: 1.3370e-04 - accuracy: 1.0000 - val_loss: 6.0619e-08 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1cd751f8fc8>"
      ]
     },
     "execution_count": 393,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x, y, batch_size=1, epochs=2, validation_data=(xx, yy), shuffle=False, callbacks=[MyCustomCallback()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
